{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4944dd-2afe-46b6-b4f4-12990d0a5aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets, model_selection, preprocessing\n",
    "tf.__version__\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#import necessary libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71304e0-0ede-4a19-a283-81d6ec37fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMSIZE = [224,224]\n",
    "BATCH = 32\n",
    "dvc_path =\"C:/Users/Yuval/anaconda3/Gilat\"\n",
    "split_sizes = {\"train\": 1000, \"validation\":1000, \"test\":1000}\n",
    "datagen = ImageDataGenerator(rescale=1/255)\n",
    "a = ''\n",
    "b = ''\n",
    "list_models = []\n",
    "list_preds = []\n",
    "\n",
    "\n",
    "def plot_images(x, y,**kwargs):\n",
    "    global a, b\n",
    "    a = pair[0]\n",
    "    b = pair[1]\n",
    "    n_pix = int(np.sqrt(np.prod(x.shape[1:3]))) #assumes images are square\n",
    "    im_indices = np.random.choice(x.shape[0], 36, replace=False) #Pick 36 images randomaly without sorting\n",
    "    fig, axes = subplots(nrows=6,ncols=6, figsize=(10,10), sharex=True, sharey=True, frameon=False)\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        curr_i = im_indices[i]\n",
    "        ax.imshow(x[curr_i].reshape(n_pix,n_pix, 3), aspect=\"auto\", **kwargs)\n",
    "        if y[curr_i]==0:\n",
    "            ax.text(10,20,pair[0], fontdict={\"backgroundcolor\": \"gray\",\"color\": \"white\" })\n",
    "        else:\n",
    "              ax.text(10,20,pair[1], fontdict={\"backgroundcolor\": \"gray\",\"color\": \"white\" })\n",
    "        #ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout(h_pad=0, w_pad=0)\n",
    "    \n",
    "def get_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = array(img).reshape([1,224,224,3]) #img = img.reshape([1,224,224,3])\n",
    "    return img  \n",
    "def build_model(pair, list_models, list_preds):\n",
    "    datagen = ImageDataGenerator(rescale=1/255)\n",
    "    plot_gen = datagen.flow_from_directory(\n",
    "    directory=dvc_path+\"/kor_gem_pila/train\",\n",
    "    target_size=IMSIZE,\n",
    "    batch_size=36,\n",
    "    class_mode='binary',\n",
    "    )   \n",
    "    x,y = next(plot_gen)\n",
    "    \n",
    "    plot_images(x, y,interpolation=\"spline16\")\n",
    "    \n",
    "    TF_IMSIZE = [50,50]\n",
    "    datagen = ImageDataGenerator(rescale=1/255,zoom_range=[0.3,0.3]) #samplewise_center=True, samplewise_std_normalization=True)\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        directory=dvc_path+\"/kor_gem_pila/train\",\n",
    "        target_size=TF_IMSIZE,\n",
    "        batch_size=BATCH,\n",
    "        classes=[a,b]) #['Kor','Pila']\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        directory=dvc_path+\"/kor_gem_pila/validation\",\n",
    "        target_size=TF_IMSIZE,\n",
    "        batch_size=1000,\n",
    "        classes=[a,b])\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 64 # 1st layer number of neurons\n",
    "    n_hidden_2 = 32 # 2nd layer number of neurons\n",
    "    num_input = np.prod(TF_IMSIZE)*3 #\n",
    "    num_classes = 2 # \n",
    "    X = tf.placeholder(\"float\", [None] + TF_IMSIZE + [3])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "    # placing them in a dictionary is helpful for keeping organized\n",
    "    # but these are just python variables.\n",
    "    weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "            'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "        }\n",
    "\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "    }\n",
    "\n",
    "    X_flat = tf.reshape(X, [tf.shape(X)[0], -1])\n",
    "\n",
    "    # Now we define the operations we'll use to construct\n",
    "    # the output from our inputs and trainable parameters\n",
    "\n",
    "    # First hidden fully connected layer\n",
    "    layer_1 = tf.matmul(X_flat, weights['h1']) + biases['b1']\n",
    "\n",
    "    # Second hidden fully connected layer\n",
    "    layer_2 = tf.matmul(layer_1, weights['h2']) + biases['b2']\n",
    "\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    logits = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "\n",
    "    tf.disable_v2_behavior()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Define the loss and optimizer\n",
    "    # recall that cross-entropy loss is what we use for most categorization problems\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n",
    "    loss_op = tf.reduce_mean(loss)\n",
    "\n",
    "    # The optimizer uses gradient descent and the backprop algorithm\n",
    "    # Most of these are just variations on Stochastic Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model (with test logits, for dropout to be disabled)\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Parameters\n",
    "    num_steps = 50 # roughly 10 epochs\n",
    "    display_step = 1#int(num_steps//20)\n",
    "\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "        loss = []\n",
    "        acc = []\n",
    "\n",
    "        for step in range(1, num_steps+1):\n",
    "            batch_x, batch_y = next(train_gen)\n",
    "            # Run optimization op (backprop)\n",
    "            _, train_loss, train_acc = sess.run([train_op, loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "            loss.append(train_loss)\n",
    "            acc.append(train_acc)\n",
    "            if step % display_step == 0:\n",
    "                x_val, y_val = next(val_gen)\n",
    "                val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: x_val, Y: y_val})\n",
    "                print(f\"Step {step}, Train: Loss={np.mean(loss):.4f}, Acc={np.mean(acc):.2%}\"\n",
    "                      f\"| Val: Loss={val_loss:.4f}, Acc={val_acc:.2%}\")\n",
    "                loss = []\n",
    "                acc = []\n",
    "        print(\"Optimization Finished!\")\n",
    "        \n",
    "     \n",
    "    TF_IMSIZE = IMSIZE\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        directory=dvc_path+\"/kor_gem_pila/train\",\n",
    "        target_size=TF_IMSIZE,\n",
    "        batch_size=BATCH,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        directory=dvc_path+\"/kor_gem_pila/validation\",\n",
    "        target_size=TF_IMSIZE,\n",
    "        batch_size=BATCH,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    \n",
    "    # Create a Keras Sequential model\n",
    "    # We do this by passing a list of layers to the Sequential model\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer(input_shape=TF_IMSIZE+[3]),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(64, activation=\"relu\", name=\"layer1\"),\n",
    "            keras.layers.Dense(32, activation=\"relu\", name=\"layer2\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.summary() #summary provides an at-a-glance look at the model we've built\n",
    "    \n",
    "    # Compile the network\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    steps = 1000 / BATCH\n",
    "    callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=.5, patience=1, verbose=1, min_lr=1e-8),\n",
    "        keras.callbacks.EarlyStopping(patience=5, verbose=1),\n",
    "    ]\n",
    "\n",
    "    model.fit_generator(\n",
    "        generator = train_gen,\n",
    "        steps_per_epoch = steps,\n",
    "        validation_data = val_gen,\n",
    "        validation_steps = steps,\n",
    "        callbacks = callbacks,\n",
    "        epochs = 3)\n",
    "    \n",
    "    \n",
    "    test_gen = datagen.flow_from_directory(\n",
    "    directory=dvc_path+\"/kor_gem_pila/test\",\n",
    "    target_size=IMSIZE,\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size=36,\n",
    "    class_mode='binary'\n",
    "    )\n",
    "    x,y = next(test_gen)\n",
    "    \n",
    "    plot_images(x, y, interpolation = \"spline16\")\n",
    "    \n",
    "    model.save(f'C:/Users/Yuval/anaconda3/Gilat/{pair[0]}{pair[1]}')\n",
    "    list_models.append(model)\n",
    "    \n",
    "    val_gen.reset()\n",
    "    \n",
    "    pred = model.predict_generator(val_gen,\n",
    "    steps=36,\n",
    "    verbose=1)\n",
    "    \n",
    "    list_preds.append(pred)\n",
    "    \n",
    "spicies = [\"Kor\",\"Gem\",\"Pila\"]\n",
    "pairs = list(itertools.combinations(spicies,2)) \n",
    "\n",
    "for pair in pairs:\n",
    "    print(f'The spicies are : {pair}')\n",
    "    build_model(pair, list_models, list_preds) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
